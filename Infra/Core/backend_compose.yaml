name: CORE_PORTFOLIO_STACK

services:
  local-ai:
    image: localai/localai:latest-aio-gpu-nvidia-cuda-12
    container_name: local-ai
    restart: always
    ports:
      - 8000:8080
    environment:
      - MODELS_PATH=/models
    volumes:
      - ./Data/localai/models:/models:cached
      - ./Data/localai/data:/usr/share/localai/backends:cached
    networks:
      - core-be-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

networks:
  core-be-net:
    driver: bridge
    name: core-be-net